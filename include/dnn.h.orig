#ifndef DNN_H
#define DNN_H
#include <vector>
#include <string>
#include "host_matrix.h"
#include "transforms.h"
#include "dataset.h"
using namespace std;

typedef host_matrix<float> mat;

enum Method{
	ALL, 
	BATCH, 
	ONE
};

enum Init{
	UNIFORM,
	NORMAL,
	RBM,
};

class DNN{
public:
	DNN();
<<<<<<< HEAD
	DNN(float learningRate,float momentum,float variance,Init init, const vector<size_t>& v, Method method);
=======
	DNN(float learningRate,float momentum,float reg,float variance,Init init, const vector<size_t>& v, Method method);
>>>>>>> 83de668d99776f89136a94a92e92e2eac338fecf
	~DNN();

	void train(Dataset& labeledData, size_t batchSize, size_t maxEpoch, float trainRation, float alpha);
	void predict(vector<size_t>& result, const mat& inputMat);
	void getHiddenForward(mat& outputMat, const mat& inputMat);

	//void setDataset(Dataset* pData);
	void setLearningRate(float learningRate);
	void setMomentum(float momentum);
<<<<<<< HEAD
=======
	void setReg(float reg);
>>>>>>> 83de668d99776f89136a94a92e92e2eac338fecf
	size_t getInputDimension();
	size_t getOutputDimension();
	size_t getNumLayers();
	void save(const string& fn);
	bool load(const string& fn);

private:
	void feedForward(mat& ouputMat, const mat& inputMat, bool train);
<<<<<<< HEAD
	void backPropagate(const mat& foutMat, float learningRate, float momentum);
=======
	void backPropagate(const mat& foutMat, float learningRate, float momentum,float regularization);
>>>>>>> 83de668d99776f89136a94a92e92e2eac338fecf

	//Dataset* _pData;
	float _learningRate;
	float _momentum;
<<<<<<< HEAD
=======
	float _reg;
>>>>>>> 83de668d99776f89136a94a92e92e2eac338fecf
	Method _method;
	vector<Transforms*> _transforms;
	
	vector<float> _validateAccuracy;

};


#endif
